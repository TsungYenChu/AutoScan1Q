{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_config' from 'tensorflow.python.eager.context' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-528b585ce6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mLoadData_lab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjobid_search_pyqum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpyqum_load_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#---------------load package of cavity search---------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mCavitySearch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_amp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmake_pha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_process\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_process\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_alt_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfind_best_ans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb_datamaker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFind_eps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdbscan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredict_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcompa_gru_db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\VScode\\AutoScan1Q\\code\\CavitySearch.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_config' from 'tensorflow.python.eager.context' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./code')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from colorama import Fore, Back\n",
    "from flask import session\n",
    "from pyqum import get_db, close_db\n",
    "from json import dumps\n",
    "#---------------load package of load_data---------------\n",
    "from LoadData_lab import jobid_search_pyqum, pyqum_load_data\n",
    "#---------------load package of cavity search---------------\n",
    "from CavitySearch import make_amp,make_pha,input_process,output_process,true_alt_info,find_best_ans,db_datamaker,Find_eps,dbscan,predict_dataset,compa_gru_db\n",
    "from numpy import array,vstack, hstack\n",
    "from pandas import Series, DataFrame, concat\n",
    "from keras.models import load_model\n",
    "from QubitFrequency import colect_cluster,cal_nopecenter,cal_distance,denoise,check_overpower,find_farest,cal_Ec_GHz,freq2idx\n",
    "#---------------load package of power dependent---------------\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import median\n",
    "from PowerDepend import outlier_detect, cloc\n",
    "#---------------load package of flux dependent---------------\n",
    "from FluxDepend import flux_load_data, fit_sin\n",
    "#---------------save jobid list in pickle---------------\n",
    "from pickle import dump,load\n",
    "#---------------process---------------\n",
    "from numpy import mean\n",
    "\n",
    "\n",
    "class Load_From_pyqum:\n",
    "    def __init__(self, jobid):\n",
    "        self.jobid = jobid\n",
    "        # self.pyqum_path, self.task = jobid_search_pyqum(self.jobid)\n",
    "        # self.pyqum_path = 'data/F_Response.pyqum(2)'\n",
    "        self.pyqum_path = r\"C:\\Users\\tsung\\OneDrive\\桌面\\data\\F_Response.pyqum(7)\"        \n",
    "    def load(self):\n",
    "        self.amp_data,self.jobid_check  = pyqum_load_data(self.pyqum_path)\n",
    "        if self.jobid == self.jobid_check:\n",
    "            print(\"JOBid \",self.jobid,\" checked\")\n",
    "        return self.amp_data\n",
    "            \n",
    "class CavitySearch:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "        # ans of prediction\n",
    "        self.answer = {}\n",
    "        self.amplitude, self.phase, self.freq = [], [], []\n",
    "        self.fig = DataFrame()\n",
    "        self.ans_array = {}\n",
    "\n",
    "    def do_analysis(self,designed):\n",
    "        I = self.dataframe['I']\n",
    "        Q = self.dataframe['Q']\n",
    "        self.freq = self.dataframe['Frequency']\n",
    "\n",
    "        self.amplitude = make_amp(I,Q)\n",
    "        self.phase = make_pha(I,Q)\n",
    "        self.fig = DataFrame(concat([Series(self.freq),Series(self.amplitude),Series(self.phase)],axis=1))\n",
    "\n",
    "        # GRU part\n",
    "        AMP = load_model('./model/GRU_AMP_Accuracy_ 96.63_.h5')\n",
    "        PHA = load_model('./model/GRU_PHA_Accuracy_ 95.01_.h5')\n",
    "\n",
    "        amp, pha, comparison = input_process(self.fig)      # frequency,amplitude,phase; comparison[no.][0] for freq start, end for comparison[no.][1] \n",
    "        self.fig.columns = ['<b>frequency(GHz)</b>','Amplitude','UPhase']\n",
    "\n",
    "        # prediction GRU\n",
    "        amp_pred = AMP.predict(amp)\n",
    "        pha_pred = PHA.predict(pha)\n",
    "\n",
    "        # result process\n",
    "        true_out ,alt = output_process(amp_pred,pha_pred,comparison)  \n",
    "        zone, voted_amp, voted_pha = true_alt_info(true_out,alt,self.fig)\n",
    "\n",
    "        gru_ans_amp, status_amp = find_best_ans(zone,voted_amp,self.fig,designed)  # status is the origin predict result with the default peak_limit = 8\n",
    "        gru_ans_pha, status_pha = find_best_ans(zone,voted_pha,self.fig,designed)\n",
    "        \n",
    "        # DBSCAN part\n",
    "        # dbscan for phase\n",
    "        inp_db = db_datamaker(self.phase,self.freq)\n",
    "        eps,mini = Find_eps(inp_db) \n",
    "        l_d_pha = dbscan(inp_db,eps,mini)\n",
    "        ture_out_db_pha = predict_dataset(l_d_pha,self.freq)\n",
    "\n",
    "        # dbscan for amplitude\n",
    "        inp_db = db_datamaker(self.amplitude,self.freq)\n",
    "        eps,mini = Find_eps(inp_db) \n",
    "        l_d_amp = dbscan(inp_db,eps,mini)\n",
    "        ture_out_db_amp = predict_dataset(l_d_amp,self.freq)\n",
    "\n",
    "        true_out_db = vstack((ture_out_db_amp,ture_out_db_pha))\n",
    "\n",
    "        zone, voted_amp, voted_pha = true_alt_info(true_out_db,alt,self.fig)\n",
    "        db_ans_amp, status_amp = find_best_ans(zone, voted_amp, self.fig, designed)\n",
    "        db_ans_pha, status_pha = find_best_ans(zone, voted_pha, self.fig, designed)\n",
    "\n",
    "        amp_ans = [gru_ans_amp,db_ans_amp]\n",
    "        pha_ans = [gru_ans_pha,db_ans_pha]\n",
    "\n",
    "        self.answer = compa_gru_db(amp_ans,pha_ans)   # answer looks: {'0':[start,end],'1':[...],...}\n",
    "        return self.answer\n",
    "\n",
    "    def give_answer_array(self,no):\n",
    "        self.ans_array = {\n",
    "        'Frequency':self.fig[self.fig[\"<b>frequency(GHz)</b>\"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['<b>frequency(GHz)</b>'],\n",
    "        'Amplitude':self.fig[self.fig[\"<b>frequency(GHz)</b>\"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['Amplitude'],\n",
    "        'UPhase':self.fig[self.fig[\"<b>frequency(GHz)</b>\"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['UPhase']\n",
    "        }\n",
    "\n",
    "class PowerDepend:\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "    def do_analysis(self):\n",
    "        model = KMeans(n_clusters=2, n_init=1, random_state=0)\n",
    "        label = model.fit_predict(self.data)\n",
    "        label_new = outlier_detect(self.data,label)\n",
    "        power_0,power_1 = cloc(label_new)\n",
    "        print(\"power : \"+\"{:.2f}\".format(data[:, 0][power_0])+\"{:<7}\".format(' dBm ; ')+\n",
    "              \"fr : \"+\"{:.2f}\".format(median(data[:, 1][label_new ==0]))+\"{:<7}\".format(' MHz ; \\n')+\n",
    "              \"power : \"+\"{:.2f}\".format(data[:, 0][power_1])+\"{:<7}\".format(' dBm ; ')+\n",
    "              \"fr : \"+\"{:.2f}\".format(median(data[:, 1][label_new ==1]))+\"{:<7}\".format(' MHz ; '))\n",
    "        self.select_power = min(data[:, 0][power_0],data[:, 0][power_1])\n",
    "        return self.select_power\n",
    "        \n",
    "class FluxDepend:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    def do_analysis(self,f_bare):\n",
    "        tol = 0.1\n",
    "        self.valid = flux_load_data(self.dataframe)\n",
    "        self.valid = self.valid.drop(self.valid[(self.valid['fr']<f_bare+tol) & (self.valid['fr']>f_bare-tol)].index)\n",
    "        ki = self.valid['fr']-f_bare\n",
    "        f_qubit = f_bare-1/ki\n",
    "        offset = self.valid['flux'][f_qubit ==f_qubit.max()]\n",
    "        f_dress = self.valid['fr'][offset.index]\n",
    "        res = fit_sin(self.valid['flux'],f_qubit)\n",
    "        period = float(res['period'])\n",
    "        print(\"{:<36}\".format(\"Final_dressed cavity frquency\"), \" : \" , \"{:>8.2f}\".format(float(f_dress)) ,\"MHz\")\n",
    "        print(\"{:<36}\".format(\"Final_bare cavity frquency\"), \" : \" , \"{:>8.2f}\".format(float(f_bare)) ,\"MHz\")\n",
    "        print(\"{:<36}\".format(\"Final_dressed cavity frquency diff.\"), \" : \" , \"{:>8.2f}\".format(float(f_dress-f_bare)) ,\"MHz\")\n",
    "        print(\"{:<36}\".format(\"Final_offset\"),\" : \",\"{:>8.2f}\".format(float(offset)),\"uA\")\n",
    "        print(\"{:<36}\".format(\"Final_period\"),\" : \",\"{:>8.2f}\".format(float(period)),\"uA\")\n",
    "    #     if plot:\n",
    "    #         import matplotlib.pyplot as plt\n",
    "    #         from numpy import linspace\n",
    "    #         plt.rcParams[\"figure.figsize\"] = [20,10]\n",
    "    #         plt.subplot(211)\n",
    "    #         plt.scatter(self.valid['flux'],self.valid['fr'],color='black', marker='o',label='real data')\n",
    "    #         plt.subplot(212)\n",
    "    #         plt.scatter(self.valid['flux'],f_qubit,color='r', marker='*',label='f_qubit')\n",
    "    #         x = linspace(self.valid['flux'].min(),self.valid['flux'].max(),200)\n",
    "    #         plt.plot(x, res[\"fitfunc\"](x), \"r-\", label=\"fit curve\", linewidth=2)\n",
    "    #         plt.xlabel(\"Flux : uA\")\n",
    "    #         plt.ylabel(\"Freq : MHz\")\n",
    "    #         # plt.ylim(self.valid['fr'].min()-.20,self.valid['fr'].max()+.20)\n",
    "    #         plt.legend()\n",
    "    #         plt.show()\n",
    "        return {\"f_dress\":float(f_dress/1000),\"f_bare\":float(f_bare/1000),\"f_diff\":float((f_dress-f_bare)/1000),\"offset\":float(offset),\"period\":float(period)}\n",
    "    \n",
    "class QubitFreq_Scan:\n",
    "    def __init__(self,dataframe):#,Ec,status,area_Maxratio,density\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "        self.fq = 0.0\n",
    "        self.Ec = 0.0\n",
    "        self.freq = 0.0\n",
    "        self.status = 0\n",
    "        self.target_freq = []\n",
    "        self.sub = []\n",
    "        self.title = ''\n",
    "        self.answer = {} # <- 0630 update\n",
    "        self.plot_items = {}\n",
    "\n",
    "\n",
    "\n",
    "    def do_analysis(self):\n",
    "        self.freq = self.dataframe['Frequency']  #for qubit  <b>XY-Frequency(GHz)</b>\n",
    "        I = self.dataframe['I']\n",
    "        Q = self.dataframe['Q']\n",
    "\n",
    "        inp_db = []\n",
    "        for i in range(I.shape[0]):\n",
    "            inp_db.append(list(hstack(([I[i]],[Q[i]]))))\n",
    "\n",
    "        # start DBSCAN\n",
    "        eps,min_samples = Find_eps(inp_db)\n",
    "        labels_db = dbscan(array(inp_db),eps,min_samples)\n",
    "\n",
    "        # output process\n",
    "        peak_susp_idx, nope_idx = colect_cluster(labels_db,mode='db')\n",
    "        nope_center = cal_nopecenter(nope_idx,I,Q)\n",
    "\n",
    "        # redefine the background\n",
    "        redef_sub = []\n",
    "        for i in range(self.freq.shape[0]):\n",
    "            redef_sub.append(cal_distance([I[i],Q[i]],nope_center))\n",
    "\n",
    "        self.sub = array(redef_sub)\n",
    "        self.title = 'Amplitude_Redefined'\n",
    "\n",
    "\n",
    "        if len(peak_susp_idx) != 0:\n",
    "\n",
    "            tip = denoise(peak_susp_idx,self.freq,self.sub)\n",
    "            #filter out the overpower case within +-0.5 std\n",
    "            overpower,_,_ = check_overpower(tip,self.sub,0.5)\n",
    "\n",
    "            if overpower == 'safe':\n",
    "                #farest 3 point in IQ\n",
    "                denoised_freq = find_farest(tip,nope_center,self.sub,I,Q,self.freq)\n",
    "\n",
    "                #calculate Ec based on farest\n",
    "                self.fq, self.Ec, self.status, self.target_freq = cal_Ec_GHz(denoised_freq,self.sub,self.freq)\n",
    "            else:\n",
    "                self.fq, self.Ec, self.status, self.target_freq = 0, 0, 0, []\n",
    "        else:\n",
    "            self.fq, self.Ec, self.status, self.target_freq = 0, 0, 0, []\n",
    "\n",
    "        self.answer = {'Fq':self.fq,'Ec':self.Ec,'Status':self.status,'Freqs':self.target_freq} \n",
    "        '''status = 0 for 0 peak detected -> overpower with high probability\n",
    "           status = 1 for 1 peak detected -> so far, a stronger xy-power again\n",
    "           status = 2 for 2 peak detected'''\n",
    "        return self.answer\n",
    "                                                                                         \n",
    "    def give_result(self):\n",
    "        farest = freq2idx(self.target_freq,self.freq)[:3]\n",
    "        self.plot_items = {\n",
    "            'Targets':self.sub[farest],\n",
    "            'Targets_Freq':self.freq[farest],\n",
    "            'Sub_Frequency':self.freq,\n",
    "            'Substrate':self.sub\n",
    "        }\n",
    "        return 0\n",
    "      \n",
    "def char_fresp_new(sparam,freq,powa,flux,dcsweepch = \"1\",comment = \"By bot\"):\n",
    "    # Check user's current queue status:\n",
    "    if session['run_clearance']:\n",
    "        print(comment)\n",
    "        wday = int(-1)\n",
    "        sparam = sparam   #S-Parameter\n",
    "        ifb = \"50\"     #IF-Bandwidth (Hz)\n",
    "        freq = freq #Frequency (GHz)\n",
    "        powa = powa    #Power (dBm)\n",
    "        fluxbias = flux   #Flux-Bias (V/A)\n",
    "        comment = comment.replace(\"\\\"\",\"\") #comment\n",
    "        PERIMETER = {\"dcsweepch\":dcsweepch, \"z-idle\":{}, \"sweep-config\":{\"sweeprate\":0.0001,\"pulsewidth\":1001e-3,\"current\":0}} # DC=YOKO\n",
    "        CORDER = {'Flux-Bias':fluxbias, 'S-Parameter':sparam, 'IF-Bandwidth':ifb, 'Power':powa, 'Frequency':freq}\n",
    "        print(CORDER)\n",
    "        # Start Running:\n",
    "        TOKEN = 'TOKEN(%s)%s' %(session['user_name'],random())\n",
    "        Run_fresp[TOKEN] = F_Response(session['people'], corder=CORDER, comment=dumps(comment, separators=(',', ':')), tag='', dayindex=wday, perimeter=dumps(PERIMETER, separators=(',', ':')))\n",
    "        return Run_cwsweep[TOKEN].jobid_analysis\n",
    "    else: return show()\n",
    "def char_cwsweep_new(sparam,freq,powa,flux,dcsweepch = \"1\",comment = \"By bot\"):\n",
    "    # Check user's current queue status:\n",
    "    if session['run_clearance']:\n",
    "        print(comment)\n",
    "        wday = int(-1)\n",
    "        sparam = sparam   #S-Parameter\n",
    "        ifb = \"50\"     #IF-Bandwidth (Hz)\n",
    "        freq = freq #Frequency (GHz)\n",
    "        powa = powa    #Power (dBm)\n",
    "        fluxbias = flux   #Flux-Bias (V/A)\n",
    "        xyfreq = \"OPT,\"\n",
    "        xypowa = \"OPT,\"\n",
    "        comment = comment.replace(\"\\\"\",\"\")\n",
    "        PERIMETER = {\"dcsweepch\":dcsweepch, \"z-idle\":{}, 'sg-locked': {}, \"sweep-config\":{\"sweeprate\":0.0001,\"pulsewidth\":1001e-3,\"current\":0}} # DC=YOKO\n",
    "        CORDER = {'Flux-Bias':fluxbias, 'XY-Frequency':xyfreq, 'XY-Power':xypowa, 'S-Parameter':sparam, 'IF-Bandwidth':ifb, 'Frequency':freq, 'Power':powa}\n",
    "        print(CORDER)\n",
    "        # Start Running:\n",
    "        TOKEN = 'TOKEN(%s)%s' %(session['user_name'],random())\n",
    "        Run_cwsweep[TOKEN] = CW_Sweep(session['people'], corder=CORDER, comment=comment, tag='', dayindex=wday, perimeter=PERIMETER)\n",
    "\n",
    "        return Run_cwsweep[TOKEN].jobid_analysis\n",
    "    else: return show()\n",
    "class Quest_command:\n",
    "    def __init__(self,sparam=\"S21,\"):\n",
    "        self.sparam = sparam\n",
    "\n",
    "    def jobnote(JOBID, note):\n",
    "        '''Add NOTE to a JOB after analyzing the data'''\n",
    "        if g.user['measurement']:\n",
    "            try:\n",
    "                db = get_db()\n",
    "                db.execute('UPDATE job SET note = ? WHERE id = ?', (note,JOBID))\n",
    "                db.commit()\n",
    "                close_db()\n",
    "                print(Fore.GREEN + \"User %s has successfully updated JOB#%s with NOTE: %s\" %(g.user['username'],JOBID,note))\n",
    "            except:\n",
    "                print(Fore.RED + Back.WHITE + \"INVALID JOBID\")\n",
    "                raise\n",
    "        else: pass\n",
    "    \n",
    "    def cavitysearch(self,dcsweepch,add_comment=\"\"):\n",
    "        jobid = char_fresp_new(sparam=self.sparam,freq = \"3 to 9 *3000\",powa = \"0\",flux = \"OPT,\",dcsweepch = \"1\",comment = \"By bot - step1 cavitysearch\\n\"+add_comment)\n",
    "        return jobid\n",
    "    def powerdepend(self,select_freq,add_comment=\"\"):\n",
    "        freq_command = \"%d to %d *200\"%select_freq[0],select_freq[1]\n",
    "        jobid = char_fresp_new(sparam=self.sparam,freq=freq_command,powa = \"-50 to 10 * 13\",flux = \"0\",dcsweepch = \"1\",comment = \"By bot - step2 power dependent\\n\"+add_comment)\n",
    "        return jobid\n",
    "    def fluxdepend(self,select_freq,select_powa,add_comment=\"\"):\n",
    "        freq_command = \"%d to %d *200\"%select_freq[0],select_freq[1]\n",
    "        jobid = char_fresp_new(sparam=self.sparam,freq=freq_command,powa = select_powa,flux = \"-300e-6 to 300e-6 * 20\",dcsweepch = \"1\",comment = \"By bot - step3 flux dependent\\n\"+add_comment)\n",
    "        return jobid\n",
    "    def qubitsearch(self,select_freq,select_flux,add_comment=\"\"):\n",
    "        freq_command = \"%d to %d *200\"%select_freq[0],select_freq[1]\n",
    "        jobid = char_cwsweep_new(sparam=self.sparam,freq = freq_command,flux = select_flux,powa = \"-10 to 10 *4 \",dcsweepch = \"1\",comment = \"By bot - step4 qubit search\\n\"+add_comment)\n",
    "        return jobid\n",
    "\n",
    "\n",
    "\n",
    "class AutoScan1Q:\n",
    "    def __init__(self,numCPW=\"3\",sparam=\"S21,\",dcsweepch = \"1\"):\n",
    "        self.jobid_dict = {\"CavitySearch\":0,\"PowerDepend\":0,\"FluxDepend\":0,\"QubitSearch\":0}\n",
    "        self.sparam = sparam\n",
    "        self.dcsweepch = dcsweepch\n",
    "        try:\n",
    "            self.numCPW = int(numCPW)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def cavitysearch(self, numCPW =\"3\"):\n",
    "        # jobid = Quest_command(self.sparam).cavitysearch(self.dcsweepch)\n",
    "        # self.jobid_dict[\"CavitySearch\"] = jobid\n",
    "        jobid =2604\n",
    "        dataframe = Load_From_pyqum(jobid).load()\n",
    "        print(dataframe)\n",
    "        self.cavity_list = CavitySearch(dataframe).do_analysis(numCPW)\n",
    "        print(self.cavity_list)\n",
    "        self.total_cavity_len = len(self.cavity_list)\n",
    "    def powerdepend(self,cavity_num):\n",
    "        jobid = Quest_command(self.sparam).powerdepend(select_freq=self.cavity_list[cavity_num],dcsweepch = self.dcsweepch,add_comment=\"with Cavity\"+str(cavity_num))\n",
    "        self.jobid_dict[\"PowerDepend\"] = jobid\n",
    "        dataframe = Load_From_pyqum(jobid).load()\n",
    "        self.select_power = PowerDepend(dataframe).do_analysis()\n",
    "        print(self.select_power)\n",
    "    def fluxdepend(self,cavity_num, f_bare):\n",
    "        jobid = Quest_command(self.sparam).fluxdepend(select_freq=self.cavity_list[cavity_num],select_powa=self.select_power,dcsweepch = self.dcsweepch,add_comment=\"with Cavity\"+str(cavity_num))\n",
    "        self.jobid_dict[\"FluxDepend\"] = jobid\n",
    "        dataframe = Load_From_pyqum(jobid).load()\n",
    "        self.wave = FluxDepend(dataframe).do_analysis(f_bare)\n",
    "        print(self.wave)\n",
    "    def qubitsearch(self,cavity_num):\n",
    "        jobid = Quest_command(self.sparam).qubitsearch(select_freq=self.cavity_list[cavity_num],select_flux=self.wave[\"offset\"],dcsweepch = self.dcsweepch,add_comment=\"with Cavity\"+str(cavity_num))\n",
    "        self.jobid_dict[\"QubitSearch\"] = jobid\n",
    "        dataframe = Load_From_pyqum(jobid).load()\n",
    "        self.qubit = Db_Scan(dataframe).do_analysis()\n",
    "        print(self.qubit)\n",
    "\n",
    "def save_class(item,path = \"save.pickle\"):\n",
    "    with open(path, 'wb') as f:\n",
    "        dump(item, f)\n",
    "def load_class(path = \"save.pickle\"):\n",
    "    with open(path, 'rb') as f:\n",
    "        item = load(f)\n",
    "    return item\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    routine = AutoScan1Q(numCPW = \"3\",sparam=\"S21,\",dcsweepch = \"1\")\n",
    "    routine.cavitysearch()\n",
    "    print(routine.cavity_list)\n",
    "    print(routine.total_cavity_len)\n",
    "    # for i in range(routine.total_cavity_len):\n",
    "    #     routine.powerdepend(i)\n",
    "    #     f_bare = mean(routine.cavity_list[str(i)])\n",
    "    #     routine.fluxdepend(i,f_bare)\n",
    "    #     routine.qubitsearch(i)\n",
    "    # id = int(input(\"id? : \"))\n",
    "    # pyqum_path,task = jobid_search_pyqum(id)\n",
    "    # amp_data,jobid  = pyqum_load_data(pyqum_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = AutoScan1Q(numCPW = \"3\",sparam=\"S21,\",dcsweepch = \"1\")\n",
    "routine.cavitysearch()\n",
    "print(routine.cavity_list)\n",
    "print(routine.total_cavity_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5de39d0f4ceb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAMP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/GRU_AMP_Accuracy_ 96.63_.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAMP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "AMP = load_model('./model/GRU_AMP_Accuracy_ 96.63_.h5')\n",
    "AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
