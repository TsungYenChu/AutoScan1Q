# -*- coding: utf-8 -*-
"""PredTool_r.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B4-oyC5EjX8myI7WdKHpO4V6ZdRiulEw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from keras.models import load_model
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from kneed import KneeLocator

# find the extreme value in 2D array
def extreme_2d(x):
  max_loc = []
  min_loc = []
  for i in range(x.shape[0]):
    ans_max = np.max(x[i])
    ans_min = np.min(x[i])
    max_loc.append(ans_max)
    min_loc.append(ans_min)
  return np.max(np.array(max_loc)),np.min(np.array(min_loc))

# 2D array normalize method
def normalize_2d(train):
  max ,min = extreme_2d(train)
  for i in range(train.shape[0]):
    for j in range(train.shape[1]):
      train[i][j] = (train[i][j] - min)/(max - min)
  return train


def normalize_1d(array):
	max = np.max(array)
	min = np.min(array)
	normalized = []
	for i in range(array.shape[0]):
		normalized.append((array[i]-min)/(max-min))
	return np.array(normalized)

# define to simplfy freq obtaining
def find_freq(freq):
  freq_txt = []
  for i in range(freq.shape[0]):
    freq_txt.append([float(freq[i][0]),float(freq[i][freq.shape[1]-1])])
  freq_txt = np.array(freq_txt)
  return freq_txt

# define the method of input process iput df must be like: [freq,amp,pha] with column name ['<b>frequency(GHz)</b>','Amplitude','UPhase']
def input_process(df):
  dfs = []  
  data_arrays = []

  for i in range(1):         #There are only 1 file
  
    if df.shape[0]%50 != 0:              
      dfs.append(pd.DataFrame(df[0:(df.shape[0]-(df.shape[0]%50))].values.astype(float))) #[0:(read.shape[0]-(read.shape[0]%len))] make the length be the 50 times
    else:
      dfs.append(pd.DataFrame(df[0:df.shape[0]].values.astype(float))) #freq,Amp,Uphase,I,Q
                
    temp = []           # There are 3 arrays in the temp : [Freq, Amp, Pha]
    for j in range(3):
      temp.append(np.array(dfs[i][j]))

 
    data_arrays.append(np.array(temp))      

  datas = np.array(data_arrays)
  # cut the file for len = 50
  shift = [0,25]
  shifted = []
  for l in shift:
    seperated = []
    for i in range(datas.shape[0]):                                 # with the freq range  "4~5 ,..."
      temp = []
      for j in range(datas.shape[1]):                               # with the label "freq,Amp,Pha" 
        temp_ = []                                   
        for k in range(0,datas.shape[2]-50-l,50):
            
          temp_.append(np.array(datas[i][j][k+l:k+l+50]))          # seperate with length = len 
        temp.append(temp_)

      seperated.append(temp)
    shifted.append(seperated)
  shifted = np.array(shifted)

# extract amplitude. phase, frequency
  amp = shifted[0][0][1]
  amp_shifted = shifted[1][0][1]
  pha = shifted[0][0][2]
  pha_shifted = shifted[1][0][2]
  freq = shifted[0][0][0]  
  freq_shifted = shifted[1][0][0]

  freq = find_freq(freq)
  freq_shifted = find_freq(freq_shifted)

  # normalize amp
  amp_norm = normalize_2d(amp)
  amp_shifted_norm = normalize_2d(amp_shifted)
  # make comparison table to compare prediction and frequency
  table = pd.concat([pd.DataFrame(freq),pd.DataFrame(amp_norm),pd.DataFrame(pha)],axis=1)
  table_shifted = pd.concat([pd.DataFrame(freq_shifted),pd.DataFrame(amp_shifted_norm),pd.DataFrame(pha_shifted)],axis=1)

  ret = pd.concat([table,table_shifted])
  amp = np.vstack([amp_norm,amp_shifted_norm])
  pha = np.vstack([pha,pha_shifted])
    
  return amp.reshape(amp.shape[0], amp.shape[1], 1), pha.reshape(pha.shape[0], pha.shape[1], 1), np.array(ret)
  

# define the peak detecting method
def thresholding_algo(y, lag, threshold, influence):
    signals = np.zeros(len(y))
    filteredY = np.array(y)
    avgFilter = [0]*len(y)
    stdFilter = [0]*len(y)
    avgFilter[lag - 1] = np.mean(y[0:lag])
    stdFilter[lag - 1] = np.std(y[0:lag])
    for i in range(lag, len(y)):             # <<< need to add the i<lag part
        if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter [i-1]:
            if y[i] > avgFilter[i-1]:
                signals[i] = 1
            else:
                signals[i] = -1

            filteredY[i] = influence * y[i] + (1 - influence) * filteredY[i-1]
            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])
            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])
        else:
            signals[i] = 0
            filteredY[i] = y[i]
            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])
            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])
    #addition below
    for i in range(len(signals)-2):
      if (signals[i] == signals[i+2] == 1) & (signals[i+1] == 0):
        signals[i+1] = 1
    for i in range(len(signals)-2):
      if (signals[i] == signals[i+2] == -1) & (signals[i+1] == 0):
        signals[i+1] = -1
    #addition above

    return dict(signals = np.asarray(signals),
                avgFilter = np.asarray(avgFilter),
                stdFilter = np.asarray(stdFilter))
    
# define predictional noise filter
def pred_filter(zone,fig):
  filter_out = []     # [[amp_filter,pha_filter],[...],...]
  for i in range(zone.shape[0]): 
    starts = zone[i][1]
    ends = zone[i][2]
    target_pha_df = fig[fig["<b>frequency(GHz)</b>"].between(starts,ends)]['UPhase']   # plot true[1]
    target_amp_df = fig[fig["<b>frequency(GHz)</b>"].between(starts,ends)]['Amplitude'] 
    target_pha_freq_df = fig[fig["<b>frequency(GHz)</b>"].between(starts,ends)]['<b>frequency(GHz)</b>']

    count = []   #[amp_filter,pha_filter]
    for j in [target_amp_df,target_pha_df]:
      window_ary = np.array(j)
      
      # Run algo with settings from above
      vote = 0
      for j in range(6,21,1):
        result = thresholding_algo(window_ary, lag=int(window_ary.shape[0]/3),threshold=j/2 , influence=0)
        score = 0 
        switch = 0
        for k in result["signals"] :
          if k == 1 or k == -1 :
            vote+=1
            score+=1
            break
        if score == switch:
          count.append([zone[i][0],vote])   #zone[i][0] is the no.
          break
      if score != switch: 
        count.append([zone[i][0],vote])

    filter_out.append(count)

  filter_amp = []
  filter_pha = []
  for i in filter_out:
    filter_amp.append(i[0])
    filter_pha.append(i[1])

  out_amp = sorted(np.array(filter_amp), key=lambda x:x[1], reverse=True)
  out_pha = sorted(np.array(filter_pha), key=lambda x:x[1], reverse=True)
  return np.array(out_amp), np.array(out_pha)


# define a function to sort according to the 'true' probability from the biggest to the smallest 
def prob_sort(amp_pred,pha_pred,true_amp,true_pha):
  amp = []
  pha = []
  if true_amp.shape[0] == 0:                                     # if its length is 0 then we cannot vstack the different size array together we should put the size all the same.
    amp.append([0,-1,1])
  else:
    for i in range(true_amp.shape[0]):
      amp.append([true_amp[i],amp_pred[true_amp[i]][0],1])  # true_amp = [idx_1,idx_2,.....], amp_pred = [prob_false , prob_true]

  if true_pha.shape[0] == 0:                                     # if its length is 0 then we cannot vstack the different size array together we should put the size all the same.
    amp.append([0,-1,2])
  else:
    for j in range(true_pha.shape[0]):
      pha.append([true_pha[j],pha_pred[true_pha[j]][0],2])
    
  amp = np.array(amp)
  pha = np.array(pha)
  if amp.shape[0] != 0 and pha.shape[0] != 0 :
    mixed = np.vstack([amp,pha])  # mix to sort
  else:
    if amp.shape[0] == 0 :
      mixed = pha
    elif pha.shape[0] == 0:
      mixed = amp
    else:
      mixed = np.array([])
    
  if mixed.shape[0] != 0:
    # sort by prob 
    sorted_mixed = np.array(sorted(mixed, key=lambda x:x[1], reverse=True))  # [1] stands for the probability 

    # delet the [a,-1,b]
    aux_idx = []
    for i in range(sorted_mixed.shape[0]):
      if sorted_mixed[i][1] == -1:
        aux_idx.append(i)
      
    sorted_mixed = np.delete(sorted_mixed,aux_idx,axis=0)
    return sorted_mixed
  else:
    return mixed


# define determin the prediction is the same peak or not >>> shift by 25 
# in given array the elements are the predicted True indexes, put the index in the compare table to check the value of amp/pha 
# because the index between non-shift & shifted is the (half length - 1) -> 'mid_index' , we can converse the shifted index to the non-shifted index by the mid_index
def detect_shift(true_amp,true_pha,amp_pred):
  mid_idx = (amp_pred.shape[0]/2)-1
  same_idx = []
  for i in range(0,true_amp.shape[0]-1,1):
    sample = true_amp[i]     
    for j in range(i+1,true_amp.shape[0],1):
      target = true_amp[j]
      if abs(target - sample) == (mid_idx):    # length - 1 = index 
        same_idx.append(j)

  true_amp = np.delete(true_amp,same_idx)
    
  same_idx = []
  for i in range(0,true_pha.shape[0]-1,1):
    sample = true_pha[i]     
    for j in range(i+1,true_pha.shape[0],1):
      target = true_pha[j]
      if abs(sample - target) == (mid_idx):
        same_idx.append(j)
    
  true_pha = np.delete(true_pha,same_idx)

  # converse the shifted to non-shifted index
  for i in range(true_amp.shape[0]):
    if true_amp[i] > mid_idx:
      true_amp[i] = true_amp[i] - mid_idx
  for j in range(true_pha.shape[0]):
    if true_pha[j] > mid_idx:
      true_pha[j] = true_pha[j] - mid_idx


  return true_amp,true_pha
# define output_process  
def output_process(amp_pred,pha_pred,comparison):     # there should be n peaks
  threshold = 0.45
  true_amp = []
  true_pha = []
  for i in range(amp_pred.shape[0]):    
    if amp_pred[i][0] > threshold:         # prediction is True
      true_amp.append(i)            # add the number into the true_amp
    else:
      pass
  true_amp = np.array(true_amp) 

  for j in range(pha_pred.shape[0]):    
    if pha_pred[j][0] > threshold:         # prediction is True
      true_pha.append(j)            # add the number into the true_amp
    else:
      pass
  true_pha = np.array(true_pha)

    
  # check is it the same peak or not
  true_amp,true_pha = detect_shift(true_amp,true_pha,amp_pred)

  # pick the both model prediction
  true = []
  overlap_index_amp = []
  overlap_index_pha = []
  for i in range(true_amp.shape[0]):
    for j in range(true_pha.shape[0]):
      if true_amp[i] == true_pha[j]:
            
        true.append([true_amp[i],comparison[true_amp[i]][0],comparison[true_amp[i]][1]])    # if AMP & PHA predict the same result, append the freq range [0]~[1]
        overlap_index_amp.append(i)
        overlap_index_pha.append(j)         # take a note for the overlap index in order to delet from the original array

  true_amp = np.delete(true_amp,overlap_index_amp)
  true_pha = np.delete(true_pha,overlap_index_pha)         #delete the overlap elements
  true = np.array(true)
  sum = []

  for i in range(true.shape[0]):
    idx = int(true[i][0])
    sum.append([idx,amp_pred[idx][0] + pha_pred[idx][0]])
  sum = np.array(sorted(np.array(sum), key=lambda x:x[1], reverse=True))

  out_true = []
  for i in range(sum.shape[0]):
    for j in range(true.shape[0]):
      if true[j][0] == sum[i][0]:
        out_true.append(true[j])
  true = np.array(out_true)

  alt_idx = prob_sort(amp_pred,pha_pred,true_amp,true_pha)  # alt_idx = [idx , prob , 1 or 2] (1 for amp ; 2 for pha)
  if alt_idx.shape[0] != 0:
    alt = []
    for k in range(alt_idx.shape[0]):
      idx = int(alt_idx[k][0])
      alt.append([idx,comparison[idx][0],comparison[idx][1],alt_idx[k][2]])
        
    return true, np.array(alt)
  else:
    return true, alt_idx

  

# define a method to determine the peak in the window is(1) whole or not(0).
# the following try to calculate the slope between each two points  
# if the peak in the window is the whole peak the slope will change rapidly (the diff. between slope_max & slope_min < 15 points)
# if the peak in the window is a part of the whole peak the slope will change slowly (the diff. between slope_max & slope_min > 15 points)  
# and at the mid-point is just the peak location
def peak_info(target_df):
  target_ary = np.array(target_df)
  
  slope = []
  for j in range(0,target_ary.shape[0]-1):
    slope.append(target_ary[j+1]-target_ary[j])
  
  max_idx = slope.index(max(slope))               # <<<< assume the peak tip should always be in the prediction  window
  min_idx = slope.index(min(slope))           
  distance = abs(max_idx - min_idx)
  
  if distance < 15:       # determine whole peak or not 
    if max_idx > min_idx :      # find the location of the tip of the peak
      loc_idx = min_idx + int(distance/2) + 1
      return loc_idx,distance
    else:
      loc_idx = max_idx + int(distance/2) + 1
      return loc_idx,distance
  else:
    if max_idx > min_idx :
      loc_idx = min_idx + int(distance/2) + 1
      return loc_idx,distance*3
    else:
      loc_idx = max_idx + int(distance/2) + 1
      return loc_idx,distance*3


# define check_output(): 0306 update 'precise the peak mark'
def check_output(corrected,fig):
  # first find the relation between data points and frequency
  freq = fig["<b>frequency(GHz)</b>"]
  freq_per_p = (np.array(freq)[-1]-np.array(freq)[0])/np.array(freq).shape[0]

  features = []
  ret_out = []
  for i in corrected :
    pha = np.array(fig[fig['<b>frequency(GHz)</b>'].between(i[1],i[2])]['UPhase'])
    freq = np.array(fig[fig['<b>frequency(GHz)</b>'].between(i[1],i[2])]['<b>frequency(GHz)</b>'])
    max_idx = np.where(np.diff(pha)==np.max(np.diff(pha)))[0][0]
    min_idx = np.where(np.diff(pha)==np.min(np.diff(pha)))[0][0]
    widgth = max_idx - min_idx
    mid = max_idx+int(abs(widgth)/2)+1 if widgth <0 else min_idx+int(abs(widgth)/2)+1
    # try to classify the upward or downward peak
    start_pha = pha[0]
    peak_pha = pha[mid]
    end_pha = pha[-1]
    fix_mid = 0
    if peak_pha > start_pha and peak_pha > end_pha:
      for j in range(mid-5,mid+5):
        if pha[j] > peak_pha :
          peak_pha = pha[j]
          fix_mid = j
        else:
          fix_mid = mid
    if peak_pha < start_pha and peak_pha < end_pha:
      for j in range(mid-5,mid+5):
        if pha[j] < peak_pha :
          peak_pha = pha[j]
          fix_mid = j
        else:
          fix_mid = mid

    features.append([i[0],freq[max_idx],freq[min_idx],fix_mid,int(freq.shape[0]/2)-1])
    ret_out.append(np.hstack([i,[freq[fix_mid]],[abs(widgth)*freq_per_p*1000*1.5]])) # *1000 to MHz fix with ~*1.5

  ret_out = np.array(ret_out)
  same = []

  for i in range(0,len(features)-1,1):
    for j in range(i+1,len(features),1):
      if features[i][1] == features[j][1] and features[i][2] == features[j][2] :
        if abs(features[i][3]-features[i][4]) < abs(features[j][3]-features[j][4]):
          same.append(features[j][0])
        else:
          same.append(features[i][0])
  
  delete_idx = []
  for i in range(ret_out.shape[0]):
    for j in range(len(same)):
      if ret_out[i][0] == same[j]:
        delete_idx.append(i)
  
  ret_out = np.delete(ret_out,delete_idx,axis=0)  # looks: [[no., start, end, tip, widgth],[...],...]
  
  # delete widgth > 30 MHz 
  del_idx = []
  for i in range(ret_out.shape[0]) :
    if ret_out[i][4] > 30:
      del_idx.append(i) 

  ret_out = np.delete(ret_out,del_idx,axis=0)

  return list(ret_out)



# define the method to put the peak in the center

def corr_peak_loc(df_start,df_end,origin_fig):

  freq = origin_fig["<b>frequency(GHz)</b>"]

  target_pha_df = origin_fig[freq.between(df_start,df_end)]['UPhase']   # plot true[1]
  target_amp_df = origin_fig[freq.between(df_start,df_end)]['Amplitude'] 
  target_freq_df = origin_fig[freq.between(df_start,df_end)]['<b>frequency(GHz)</b>']
  target = pd.concat([target_freq_df,target_amp_df,target_pha_df],axis=1)

  tip_loc_pha,distance_pha = peak_info(target_pha_df)
  tip_loc_amp,distance_amp = peak_info(target_amp_df)

  tip_freq_pha = np.array(target)[tip_loc_pha][0]
  tip_freq_amp = np.array(target)[tip_loc_amp][0]
  tip_idx_pha = origin_fig.index[origin_fig["<b>frequency(GHz)</b>"] == tip_freq_pha][0]
  tip_idx_amp = origin_fig.index[origin_fig["<b>frequency(GHz)</b>"] == tip_freq_amp][0]
  # donsider the edge
  if tip_idx_amp-(distance_amp*7) < 0:
    amp_left_edge = 0
  else:
    amp_left_edge = tip_idx_amp-(distance_amp*7)
  if tip_idx_amp+(distance_amp*7) > (np.array(origin_fig).shape[0]-1) :
    amp_right_edge = np.array(origin_fig).shape[0]-1
  else:
    amp_right_edge = tip_idx_amp+(distance_amp*7)

  if tip_idx_pha-(distance_pha*7) < 0:
    pha_left_edge = 0
  else:
    pha_left_edge = tip_idx_pha-(distance_pha*7)
  if tip_idx_pha+(distance_pha*7) > (np.array(origin_fig).shape[0]-1) :
    pha_right_edge = np.array(origin_fig).shape[0]-1
  else:
    pha_right_edge = tip_idx_pha+(distance_pha*7)
  
  
  amp_df = pd.DataFrame(np.array(origin_fig.iloc[amp_left_edge:amp_right_edge,:3]),columns=['Frequency(GHz)','Amplitude','UPhase'])
  pha_df = pd.DataFrame(np.array(origin_fig.iloc[pha_left_edge:pha_right_edge,:3]),columns=['Frequency(GHz)','Amplitude','UPhase'])



  amp_head = np.array(amp_df['Frequency(GHz)'])[0]
  amp_tail = np.array(amp_df['Frequency(GHz)'])[-1]
  pha_head = np.array(pha_df['Frequency(GHz)'])[0]
  pha_tail = np.array(pha_df['Frequency(GHz)'])[-1]

 
  if distance_pha <= distance_amp:
    return pha_head, pha_tail
  else:
    return amp_head, amp_tail



# define the output plot 
# define the output plot 
def true_alt_info(true,alt,origin_fig):  # true : [[no., start_freq, end_freq],[...],...]
  zone_true = []                         # alt : [[no., start_freq, end_freq, 1 or 2],[...],...]

  if (true.shape[0] != 0) :
    for i in range(true.shape[0]):
      true_start = true[i][1]
      true_end = true[i][2]
  # contract the values between the given frequency range 
      head, tail = corr_peak_loc(true_start,true_end,origin_fig)

      zone_true.append([i+1,head,tail,0])

    zone = np.vstack([np.array(zone_true),alt])

  else:
    zone = alt

  voted_amp ,voted_pha = pred_filter(zone,origin_fig)
  return zone, voted_amp, voted_pha

def ZscoreFilter(zone,voted,origin_fig,peak_limit):
 
  # pick up the range > peak_limit 
  peak = []
  for i in voted:
    if i[1] >= peak_limit:
      peak.append(i[0])

  # the following will return the freq range
  ret = []
  for i in peak:
    for j in zone:  
      if i == j[0]:
        ret.append([j[1],j[2],j[3]])
        break
  corrected = []
  for i in range(len(ret)):
    if ret[i][2] != 0: # 0 means that the peak has already in the center
      df_start = ret[i][0]
      df_end = ret[i][1]
  # contract the values between the given frequency range 
      head, tail = corr_peak_loc(df_start,df_end,origin_fig)
      corrected.append([i+1,head,tail])

    else:
      corrected.append([i+1,ret[i][0],ret[i][1]])
  
  ret_corr = check_output(np.array(corrected),origin_fig)


  return ret_corr, np.array(zone)

def test(true,designed):  # designed is the no. of cavities should exist, not observed
  range = []
  for i in true:
    range.append([i[1],i[2],i[3]])
  if designed!=0:
    if len(true) > designed:
      status = 'More'
    elif len(true) < designed:
      status = 'Less'
    else:
      status = 'Perfect'
  else:
    status = 'NONE'
  return range, status     # if len(status) == 0 means 'no given designed frequency' or 'detected = designed'

  
def find_best_ans(zone,voted,fig,designed):
  peak_limit = 8
  last_status, status = 'default', 'zscoring !'
  last_true, true, range = [], [], []
  step = 0 
  ori_status = ''
  haha, _ = ZscoreFilter(zone,voted,fig,peak_limit)
  _, ori_status = test(haha,designed)  # <- give the origin status as the peak_limit=8 

  while len(status) != 0:
    true, _ = ZscoreFilter(zone,voted,fig,peak_limit)
  
    # when true is empty means no peaks
    if true==[]:
      break
    # when less -> more turning point! 
    if last_status != status and last_status != 'default':
      break

    range, status = test(true,designed)
    # less means tp lower limit , more means to increase limit
    if status=='Less':
      peak_limit-=1
      if peak_limit < 6:
        break
    elif status=='More':
      peak_limit+=1
      if peak_limit > 16:
        break
    else:
      break
    # when lower a limit get the data more than we need
    if abs(len(last_true) - designed) < abs(len(last_true)-len(true)) and last_status != 'default':
      true = last_true[-1]
      range, status = test(true,designed)
      break

    last_status = status
    # determine new_true to be memory
    if len(last_true)!=0:
      len_rec = []
      for i in last_true:
        if len(true) != len(i):
          len_rec.append(1)
        else:
          len_rec.append(0)
      if all(len_rec) and true!= []:
        last_true.append(true)
    else:
      last_true.append(true)
   
    # do more than 10 times break!
    if step==10:
      range, status = test(last_true[-1],designed)
      break

    step+=1
 

  return range, ori_status

# input dbscan data maker
def db_datamaker(sub,freq):
  X = []
  Y = []

  for i in range(freq.shape[0]):
    X.append([sub[i]])
    Y.append([freq[i]])

  return np.hstack([np.array(X),np.array(Y)])


def Find_eps(inp_db):
    data = np.array(inp_db)
    neighbors = 2 
    nbrs = NearestNeighbors(n_neighbors=neighbors ).fit(data)
    distances, indices = nbrs.kneighbors(data)
    distance_desc = sorted(distances[:,neighbors-1], reverse=True)
    #plt.plot(list(range(1,len(distance_desc )+1)),distance_desc )
    #plt.show()

    kneedle = KneeLocator(range(1,len(distance_desc)+1),  #x values
                      distance_desc, # y values
                      S=1, #parameter suggested from paper
                      curve="convex", #parameter from figure
                      direction="decreasing") #parameter from figure
    eps = distance_desc[kneedle.elbow]  
    return eps,neighbors

def dbscan(inp,eps,min_samples):
  labels = DBSCAN(eps=eps,min_samples=min_samples).fit(inp).labels_

  return labels



#### Warning:: Important !!!! do NOT delete !!!
def predict_dataset(label_db,freq):
  b = []
  for i in range(len(label_db)):
    if label_db[i]==-1:
      b.append(freq[i])
  b = sorted(b)


  p2p = (freq.max()-freq.min())/freq.shape[0]

  dataset = [] # dataset=[[freq,...],[freq,...],......]
  while len(b) != 0:

    in_50mhz = []
    in_50mhz.append(b[0])
    del_item = []
    for j in range(1,len(b),1):
        if abs(b[j] - b[0]) < 50*p2p:
          in_50mhz.append(b[j])
          del_item.append(b[j])
    del_item.append(b[0])
    dataset.append(in_50mhz)

    for j in del_item:
      b.remove(j)


  after_output_process_array = []    # <- try to connect the function have designed already [[no., start_freq, end_freq],[...],...]
  n = 1
  for i in dataset:
    i.sort()
    left_bound = i[0]-5*p2p  
    right_bound = i[0]+5*p2p
    if left_bound > freq[0] and right_bound < freq.max():   # if the freq near the freq boundary it should be a noise
        after_output_process_array.append([n/10,left_bound,right_bound])
        n+=1
  
  return np.array(after_output_process_array)
########## importane area end



def extract_same_cavity(ans_a,ans_b):  # input looks : [[start,end,loc],[...],...]
  samecavity = []
  if len(ans_a)>len(ans_b):
    A = np.array(ans_a)  # <- range array A[i][2] is the peak location
    B = np.array(ans_b)
  else:
    A = np.array(ans_b)  # <- range array A[i][2] is the peak location
    B = np.array(ans_a)


  if B.shape[0] !=0:
    for i in range(A.shape[0]):
      for j in range(B.shape[0]):
        if A[i][2] == B[j][2]:  # same cavity location
          samecavity.append(i)
  elif B.shape[0]==0 and A.shape[0]!=0:
    for i in range(A.shape[0]):
      samecavity.append(i)
  else:
    samecavity.append([])

  if len(samecavity) != 0:
    u, i = np.unique(samecavity, return_inverse=True)
    repeator = u[np.bincount(i) > 1]
    for i in repeator:
      rep_idx = samecavity.index(i)
      samecavity.pop(rep_idx)

    final_ans = []
    for i in samecavity:
      final_ans.append(list(A[i]))   

    return np.array(final_ans)    # looks: [[start,end,loc],[...],...]
  else:
    return np.array([0,0,0])
    
# the answer will be the value with gru&db all predict true
def compa_gru_db(amp_ans,pha_ans):

  amp_same = extract_same_cavity(amp_ans[0],amp_ans[1])
  pha_same = extract_same_cavity(pha_ans[0],pha_ans[1])
  all_same = np.vstack((amp_same,pha_same))

  checkpoint = all_same[:,2]   # check peak loc repeater 
  # delete repeator
  u, i = np.unique(checkpoint, return_inverse=True)
  repeator = u[np.bincount(i) > 1]

  rep_idx = []
  for i in repeator:
    rep_idx.append(list(checkpoint).index(i))
  
  all_same = np.delete(all_same,rep_idx,axis=0)

  # delete with zero list
  zero_idx = []
  for i in range(all_same.shape[0]):
    if not all(all_same[i]):
      zero_idx.append(i)

  all_same = np.delete(all_same,zero_idx,axis=0)
  
  denoised = []
  # delete freq<3.5 or freq > 8.5
  for i in range(all_same.shape[0]):
    if all_same[i][2]>=8.5 or all_same[i][2]<=3.5:
      denoised.append(i)
  all_same = np.delete(all_same,denoised,axis=0)
  ans_dict = {}
  
  for i in range(all_same.shape[0]):
    ans_dict[str(all_same[i][2]*1000)+' MHz']=[all_same[i][0],all_same[i][1]]
    
  return ans_dict  # [[start,end,loc],[...],...]  return only in the looks: {'loc_1':[start,end],'loc_2':[...],...}

def make_amp(I,Q):
  amp = []
  for i in range(I.shape[0]):
    amp.append(20*np.log10((I[i]**2+Q[i]**2)**0.5))
  return np.array(amp)

def make_pha(I,Q):
  after = np.unwrap(np.arctan2(Q,I),period=2*np.pi)
  dif = np.diff(after)
  pha = np.hstack((dif,dif[-1]))

  return normalize_1d(pha)



class CavitySearch():
    def __init__(self, quantificationObj, *args,**kwargs):
        self.quantificationObj = quantificationObj

        # ans of prediction
        self.answer = {}
        self.amplitude, self.phase, self.freq = [], [], []
        self.fig = pd.DataFrame()


    def do_analysis(self,designed):
        I = self.quantificationObj.rawData["iqSignal"][0].real
        Q = self.quantificationObj.rawData["iqSignal"][0].imag
        self.freq = self.quantificationObj.rawData["x"]

        self.amplitude = make_amp(I,Q)
        self.phase = make_pha(I,Q)
        self.fig = pd.DataFrame(pd.concat([pd.Series(self.freq),pd.Series(self.amplitude),pd.Series(self.phase)],axis=1))

        # GRU part
        AMP = load_model('../model/GRU_AMP_Accuracy_ 96.63_.h5')
        PHA = load_model('../model/GRU_PHA_Accuracy_ 95.01_.h5')

        amp, pha, comparison = input_process(self.fig)      # frequency,amplitude,phase; comparison[no.][0] for freq start, end for comparison[no.][1] 
        self.fig.columns = ['<b>frequency(GHz)</b>','Amplitude','UPhase']

        # prediction GRU
        amp_pred = AMP.predict(amp)
        pha_pred = PHA.predict(pha)

        # result process
        true_out ,alt = output_process(amp_pred,pha_pred,comparison)  
        zone, voted_amp, voted_pha = true_alt_info(true_out,alt,self.fig)

        gru_ans_amp, status_amp = find_best_ans(zone,voted_amp,self.fig,designed)  # status is the origin predict result with the default peak_limit = 8
        gru_ans_pha, status_pha = find_best_ans(zone,voted_pha,self.fig,designed)
        
        # DBSCAN part
        # dbscan for phase
        inp_db = db_datamaker(self.phase,self.freq)
        eps,mini = Find_eps(inp_db) 
        l_d_pha = dbscan(inp_db,eps,mini)
        ture_out_db_pha = predict_dataset(l_d_pha,self.freq)

        # dbscan for amplitude
        inp_db = db_datamaker(self.amplitude,self.freq)
        eps,mini = Find_eps(inp_db) 
        l_d_amp = dbscan(inp_db,eps,mini)
        ture_out_db_amp = predict_dataset(l_d_amp,self.freq)

        true_out_db = np.vstack((ture_out_db_amp,ture_out_db_pha))

        zone, voted_amp, voted_pha = true_alt_info(true_out_db,alt,self.fig)
        db_ans_amp, status_amp = find_best_ans(zone, voted_amp, self.fig, designed)
        db_ans_pha, status_pha = find_best_ans(zone, voted_pha, self.fig, designed)

        amp_ans = [gru_ans_amp,db_ans_amp]
        pha_ans = [gru_ans_pha,db_ans_pha]

        self.answer = compa_gru_db(amp_ans,pha_ans)   # answer looks: {'0':[start,end],'1':[...],...}

    def plot_answer(self,no):
        plt.plot(self.fig[self.fig["<b>frequency(GHz)</b>"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['<b>frequency(GHz)</b>'],self.fig[self.fig["<b>frequency(GHz)</b>"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['Amplitude'],c='r')
        plt.title('Amplitude')
        plt.show()
        plt.plot(self.fig[self.fig["<b>frequency(GHz)</b>"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['<b>frequency(GHz)</b>'],self.fig[self.fig["<b>frequency(GHz)</b>"].between(self.answer[str(no)][0],self.answer[str(no)][1])]['UPhase'])
        plt.title('UPhase')
        plt.show()
